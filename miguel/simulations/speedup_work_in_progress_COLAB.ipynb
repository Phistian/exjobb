{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGK9HjpkW/bdb5cOHu4iKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phistian/exjobb/blob/main/miguel/simulations/speedup_work_in_progress_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "  !git clone https://github.com/Phistian/exjobb\n",
        "  !git config --global user.email \"christianrut42@gmail.com\"\n",
        "  !git config --global user.name \"Phistian\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  cur_path = Path(\"/content/exjobb/miguel/simulations\")\n",
        "else:\n",
        "  cur_path = Path(__file__)\n",
        "\n",
        "\n",
        "parent_path = cur_path.parent.resolve()\n",
        "exjobb_address = str(parent_path) + \"/../\"\n",
        "spatial_address = str(parent_path) + '/spatial_gnns/'\n",
        "datasets_address = str(parent_path) + '/datasets/'\n",
        "histories_address = str(parent_path) + '/training_results/saved_histories/'\n",
        "models_address = str(parent_path) + '/training_results/saved_models/'\n",
        "sys.path.append(spatial_address)\n",
        "sys.path.append(str(parent_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORv9B-6dieu7",
        "outputId": "9a830172-65dc-4233-98ab-20d6f58f17cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exjobb'...\n",
            "remote: Enumerating objects: 759, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 759 (delta 94), reused 149 (delta 83), pack-reused 593\u001b[K\n",
            "Receiving objects: 100% (759/759), 72.77 MiB | 25.16 MiB/s, done.\n",
            "Resolving deltas: 100% (443/443), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates, orientations = get_particles()"
      ],
      "metadata": {
        "id": "qiaU_hJHPBpZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "from pathlib import Path\n",
        "import matplotlib.cm as cm\n",
        "import cProfile\n",
        "import re\n",
        "\n",
        "##INFO\n",
        "\n",
        "##PARAMETERS\n",
        "rho = 0.2  # total particle area to box_area ratio  ρ ∈ {0.1, 0.6}\n",
        "F_P = 3\n",
        "N = 5  # for its= 1e2, sample_its = 100: 50 11, 100 46\n",
        "its = int(1e3)  # 1e5\n",
        "sample_its = 4\n",
        "n_resets = 0  # including first run\n",
        "interact_across_borders = True\n",
        "potential_type = 'tslj'\n",
        "plot = False\n",
        "plot_last_frame = False\n",
        "save = False\n",
        "rho_area = True\n",
        "profile = True\n",
        "\n",
        "##VARIABLES AND CONSTANTS\n",
        "its_per_reset = int(its / (n_resets + 1))\n",
        "reset_indices = np.linspace(its_per_reset, its - its_per_reset, n_resets, dtype=int)\n",
        "sample_indices_vector = np.linspace(0, its - 1, sample_its, dtype=int)\n",
        "boltzmann = 1\n",
        "energy_parameter = 1\n",
        "# temperature = 0.01\n",
        "diffusion_translational = 0.01\n",
        "diffusion_rotational = 1  # Dr ∈ {0.25, 1.0}\n",
        "dt = 1e-5\n",
        "length_scale = 1\n",
        "interaction_radius = 3 * length_scale\n",
        "duplicate_search_threshold = interaction_radius\n",
        "dx = length_scale / 10000\n",
        "\n",
        "if rho_area:\n",
        "  one_particle_area = (length_scale / 2) ** 2 * np.pi\n",
        "  box_area = N * one_particle_area / rho\n",
        "  box_len = np.sqrt(box_area)\n",
        "  if box_len < duplicate_search_threshold:\n",
        "      raise Exception(\"The box length is very small in comparison to the interaction radius\")\n",
        "else:\n",
        "  box_len = N/rho\n",
        "\n",
        "\n",
        "def get_min_dist_vectors_mtx(coords):\n",
        "    x = coords[:, 0]\n",
        "    y = coords[:, 1]\n",
        "    dx = np.subtract(np.broadcast_to(x, (len(x), len(x))), np.broadcast_to(x[:, np.newaxis], (len(x), len(x))))\n",
        "    dx = np.mod(dx + 0.5*box_len, box_len) - 0.5*box_len\n",
        "    dy = np.subtract(np.broadcast_to(y, (len(y), len(y))), np.broadcast_to(y[:, np.newaxis], (len(y), len(y))))\n",
        "    dy = np.mod(dy + 0.5*box_len, box_len) - 0.5*box_len\n",
        "    dist_min = np.stack((dx, dy), axis=0)\n",
        "    return dist_min\n",
        "\n",
        "def v_mtx_to_d_mtx(v_mtx):\n",
        "    sq_v = np.square(v_mtx)\n",
        "    sq_d = np.sum(sq_v, axis=0)\n",
        "    d = np.sqrt(sq_d)\n",
        "    return d\n",
        "\n",
        "def get_distance_matrix(coords):\n",
        "    d = v_mtx_to_d_mtx(get_min_dist_vectors_mtx(coords))\n",
        "    return d\n",
        "\n",
        "def get_distances_until_chosen_particle(chosen_particle, coords):\n",
        "    x = coords[:chosen_particle, 0]\n",
        "    y = coords[:chosen_particle, 1]\n",
        "    dx = np.subtract(np.broadcast_to(coords[chosen_particle,0], (len(x),)), x)\n",
        "    dx = np.where(dx > 0.5 * box_len, dx - box_len, np.where(dx < -0.5 * box_len, dx + box_len, dx))\n",
        "    dy = np.subtract(np.broadcast_to(coords[chosen_particle,1], (len(y),)), y)\n",
        "    dy = np.where(dy > 0.5 * box_len, dy - box_len, np.where(dy < -0.5 * box_len, dy + box_len, dy))\n",
        "    dist = np.sqrt(dx**2 + dy**2)\n",
        "    return dist\n",
        "\n",
        "def get_particles(n_particles=N):\n",
        "    coordinates = np.random.uniform(-box_len / 2, box_len / 2, size=(n_particles, 2))\n",
        "    collision_present = True\n",
        "\n",
        "    for i in range(1, n_particles):\n",
        "        D = get_distances_until_chosen_particle(i, coordinates)\n",
        "        threshold = length_scale * 1.1\n",
        "        collision_mtx = np.where(D < threshold, 1, 0)\n",
        "        while collision_mtx.any():\n",
        "            coordinates[i, :] = np.random.uniform(-box_len / 2, box_len / 2, 2)\n",
        "            D = get_distances_until_chosen_particle(i, coordinates)\n",
        "            collision_mtx = np.where(D < threshold, 1, 0)\n",
        "    orientations = np.random.uniform(low=0, high=2 * np.pi, size=(n_particles, 1))\n",
        "    return coordinates, orientations\n",
        "\n",
        "\n",
        "##POTENTIALS AND THEIR GRADIENTS - FUNCTIONS\n",
        "def get_lj_truncation_value(truncation_distance):\n",
        "    return get_lj_potential(truncation_distance)\n",
        "\n",
        "\n",
        "def get_lj_potential(distance, truncation_distance=box_len, truncation_value=0):\n",
        "    if distance < truncation_distance:\n",
        "        potential = 4 * energy_parameter * ((1 / distance) ** 12 - (1 / distance) ** 6) - truncation_value\n",
        "    else:\n",
        "        potential = 0\n",
        "    return potential\n",
        "def Mget_lj_potential(D, inv_D, truncation_distance=box_len, truncation_value=0):\n",
        "    zero_mask = D > truncation_distance\n",
        "    potentials = 4 * energy_parameter * ((inv_D) ** 12 - (inv_D) ** 6) - truncation_value\n",
        "    potentials = zero_mask * potentials\n",
        "    #potentials = np.where(D < truncation_distance, 4 * energy_parameter * ((1/D) ** 12 - (1/D) ** 6) - truncation_value, 0)\n",
        "    return potentials\n",
        "\n",
        "\n",
        "\n",
        "def get_lj_potential_gradient(distance_vector, truncation_distance, truncation_value):\n",
        "    distance = np.sqrt(distance_vector.dot(distance_vector))\n",
        "    difference = get_lj_potential(distance + dx, truncation_distance, truncation_value) - get_lj_potential(\n",
        "        distance - dx, truncation_distance, truncation_value)\n",
        "    gradient_magnitude = difference / (2 * dx)\n",
        "    gradient = gradient_magnitude * -distance_vector / distance  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    return gradient\n",
        "def Mget_lj_potential_gradient(S, D, truncation_distance, truncation_value):\n",
        "    Dplus = D + dx\n",
        "    Dminus = D - dx\n",
        "    inv_D = 1/D\n",
        "    Vplus = Mget_lj_potential(Dplus, inv_D, truncation_distance, truncation_value)\n",
        "    Vminus = Mget_lj_potential(Dminus, inv_D, truncation_distance, truncation_value)\n",
        "    differences = Vplus - Vminus\n",
        "    gradient_magnitudes = differences / (2 * dx)\n",
        "    gradient_magnitudes = np.stack((gradient_magnitudes, gradient_magnitudes), axis=0)\n",
        "    Dstacked = np.stack((inv_D,inv_D), axis=0)\n",
        "    gradients = gradient_magnitudes * -S / Dstacked  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    np.fill_diagonal(gradients[0,:,:], 0)\n",
        "    np.fill_diagonal(gradients[1, :, :], 0)\n",
        "    return gradients\n",
        "\n",
        "\n",
        "def get_tslj_potential(distance):\n",
        "    return get_lj_potential(distance, truncation_distance=2.5, truncation_value=get_lj_truncation_value(2.5))\n",
        "\n",
        "\n",
        "def get_tslj_potential_gradient(distance_vector):\n",
        "    return get_lj_potential_gradient(distance_vector, truncation_distance=2.5,\n",
        "                                     truncation_value=get_lj_truncation_value(2.5))\n",
        "def Mget_tslj_potential_gradient(S, D, truncation_distance, truncation_value):\n",
        "    return Mget_lj_potential_gradient(S, D, truncation_distance=truncation_distance,\n",
        "                                     truncation_value=truncation_value)\n",
        "\n",
        "\n",
        "def get_wca_potential(distance):\n",
        "    r_cut = length_scale * (2 ** (1 / 6))\n",
        "    return get_lj_potential(distance, truncation_distance=r_cut, truncation_value=get_lj_truncation_value(r_cut))\n",
        "\n",
        "\n",
        "def get_wca_potential_gradient(distance_vector):\n",
        "    r_cut = length_scale * 2 ** (1 / 6)\n",
        "    return get_lj_potential_gradient(distance_vector, truncation_distance=r_cut,\n",
        "                                     truncation_value=get_lj_truncation_value(r_cut))\n",
        "def Mget_wca_potential_gradient(S, D):\n",
        "    r_cut = length_scale * 2 ** (1 / 6)\n",
        "    return Mget_lj_potential_gradient(S, D, truncation_distance=r_cut,\n",
        "                                     truncation_value=get_lj_truncation_value(r_cut))\n",
        "\n",
        "\n",
        "def get_srs_potential(r, n=14, k0=10 / length_scale, eps_s=1, sig_s=2.5):\n",
        "    return energy_parameter * (length_scale / r) ** n + 1 / 2 * eps_s * (1 - np.tanh(k0 * (r - sig_s)))\n",
        "\n",
        "\n",
        "def get_srs_potential_gradient(distance_vector):\n",
        "    distance = np.sqrt(distance_vector.dot(distance_vector))\n",
        "    difference = get_srs_potential(distance + dx) - get_srs_potential(distance - dx)\n",
        "    gradient_magnitude = difference / (2 * dx)\n",
        "    gradient = gradient_magnitude * -distance_vector / distance  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    return gradient\n",
        "def Mget_srs_potential_gradient(S, D): ##TODO FINISH THIS\n",
        "    distance = np.sqrt(S.dot(S))\n",
        "    difference = get_srs_potential(distance + dx) - get_srs_potential(distance - dx)\n",
        "    gradient_magnitude = difference / (2 * dx)\n",
        "    gradient = gradient_magnitude * -S / distance  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    return gradient\n",
        "\n",
        "\n",
        "def get_potential(distance, key):\n",
        "    if key == 'tslj':\n",
        "        return get_tslj_potential(distance)\n",
        "    elif key == 'wca':\n",
        "        return get_wca_potential(distance)\n",
        "    elif key == 'srs':\n",
        "        return get_srs_potential(distance)\n",
        "\n",
        "\n",
        "def get_potential_gradient(distance_vector, key):\n",
        "    if key == 'tslj':\n",
        "        return get_tslj_potential_gradient(distance_vector)\n",
        "    elif key == 'wca':\n",
        "        return get_wca_potential_gradient(distance_vector)\n",
        "    elif key == 'srs':\n",
        "        return get_srs_potential_gradient(distance_vector)\n",
        "\n",
        "def Mget_potential_gradients(S, D, key, **kwargs):\n",
        "    if key == 'tslj':\n",
        "        return Mget_tslj_potential_gradient(S, D, **kwargs)\n",
        "    elif key == 'wca':\n",
        "        return Mget_wca_potential_gradient(S, D)\n",
        "    elif key == 'srs':\n",
        "        return Mget_srs_potential_gradient(S, D)\n",
        "\n",
        "    ##GET INFO - FUNCTIONS\n",
        "\n",
        "\n",
        "def get_velocity(orientation, f_p, summed_gradients_vector):\n",
        "    # thermal_force = np.sqrt(2*diffusion_translational) * np.random.randn(2)  #~0.1\n",
        "    active_force = np.squeeze(np.array([np.cos(orientation), np.sin(orientation)]) * f_p)  # ~0.3\n",
        "    passive_force = -summed_gradients_vector  # diffusion_translational * -summed_gradients_vector  #varies based on density\n",
        "    # print(passive_force)\n",
        "\n",
        "    return active_force + passive_force\n",
        "\n",
        "\n",
        "def get_velocity_separated(orientation, f_p, summed_gradients_vector):\n",
        "    # thermal_force = np.sqrt(2*diffusion_translational) * np.random.randn(2)  #~0.1\n",
        "    active_force = np.squeeze(np.array([np.cos(orientation), np.sin(orientation)]) * f_p)  # ~0.3\n",
        "    passive_force = -summed_gradients_vector  # varies based on density\n",
        "    # print(passive_force)\n",
        "\n",
        "    return active_force + passive_force, active_force, passive_force\n",
        "def Mget_velocity_separated(orientations, f_p, summed_gradients):\n",
        "    cospart = np.cos(orientations)\n",
        "    sinpart = np.sin(orientations)\n",
        "    active_force = np.concatenate((cospart, sinpart), axis=1) * f_p  # ~0.3\n",
        "\n",
        "\n",
        "    passive_force = -summed_gradients  # varies based on density\n",
        "    # print(passive_force)\n",
        "\n",
        "    return active_force + passive_force, active_force, passive_force\n",
        "\n",
        "\n",
        "def get_energies(coordinates, orientations, velocities, truncation_distance, truncation_value, t):  # OLD AND UNUSED\n",
        "    n_particles = coordinates.shape[0]\n",
        "    new_coordinates = coordinates\n",
        "    new_orientations = orientations\n",
        "    saved_distances = np.zeros(shape=(n_particles, n_particles, 2))\n",
        "    kinetic_energy = 0\n",
        "    potential_energy = 0\n",
        "\n",
        "    for i, pos0 in enumerate(coordinates):\n",
        "        gradients_sum = np.zeros(2)\n",
        "        for j, pos1 in enumerate(coordinates):\n",
        "            d_v = pos1 - pos0\n",
        "            saved_distances[i, j, :] = d_v\n",
        "            if d_v[0] < duplicate_search_threshold and d_v[1] < duplicate_search_threshold and i != j:\n",
        "                gradients_sum += get_lj_potential_gradient(d_v, truncation_distance, truncation_value)\n",
        "            if i != j:\n",
        "                d = np.sqrt(d_v.dot(d_v))\n",
        "                potential_energy += get_lj_potential(d, truncation_distance, truncation_value)\n",
        "\n",
        "        velocity = get_velocity(orientations[i], F_P, gradients_sum)\n",
        "        kinetic_energy += velocity.dot(velocity)  # m = 1\n",
        "    kinetic_energy = kinetic_energy / 2\n",
        "    potential_energy = potential_energy / 2\n",
        "    total_energy = kinetic_energy + potential_energy\n",
        "\n",
        "    return kinetic_energy, potential_energy, total_energy\n",
        "\n",
        "\n",
        "##UPDATING - FUNCTIONS\n",
        "def update_data(coordinates, orientations, potential_key, t, **kwargs):\n",
        "    \n",
        "    try:\n",
        "      truncation_distance = kwargs[\"truncation_distance\"]\n",
        "      truncation_value = kwargs[\"truncation_value\"]\n",
        "    except:\n",
        "      print(\"no truncation\")\n",
        "\n",
        "    new_coordinates = coordinates.copy()\n",
        "    new_orientations = orientations.copy()\n",
        "    \n",
        "    S = -get_min_dist_vectors_mtx(coordinates)\n",
        "    D = v_mtx_to_d_mtx(S)\n",
        "    \n",
        "    gradients = Mget_potential_gradients(S, D, potential_key, truncation_distance=truncation_distance, truncation_value=truncation_value)\n",
        "    \n",
        "    gradient_sums = np.sum(gradients, axis=-1)\n",
        "    gradient_sums = gradient_sums.T\n",
        "    v, active_v, passive_v = Mget_velocity_separated(orientations, F_P, gradient_sums)\n",
        "    \n",
        "    angular_diffusion_steps = np.sqrt(2 * diffusion_rotational * dt) * np.random.randn(N, 1)\n",
        "    diffusion_steps = np.sqrt(dt * diffusion_translational * 2) * np.random.randn(N, 2)\n",
        "    new_coordinates += dt * v + diffusion_steps\n",
        "    new_orientations += angular_diffusion_steps\n",
        "\n",
        "    new_coordinates_x = new_coordinates[:, 0]\n",
        "    new_coordinates_y = new_coordinates[:, 1]\n",
        "    \n",
        "    new_coordinates_x = new_coordinates_x % box_len - 0.5 * box_len\n",
        "    new_coordinates_y = new_coordinates_y % box_len - 0.5 * box_len\n",
        "    new_coordinates[:, 0] = new_coordinates_x\n",
        "    new_coordinates[:, 1] = new_coordinates_y\n",
        "\n",
        "    new_orientations = new_orientations % (2 * np.pi)\n",
        "    \n",
        "    \n",
        "    new_solutions = np.sqrt(v[:,0]**2 + v[:,1]**2)\n",
        "    \n",
        "    return new_coordinates, new_orientations, new_solutions\n",
        "\n",
        "\n",
        "##SIMULATION\n",
        "## Arrays to save stuff into\n",
        "\n",
        "\n",
        "def run(coordinates, orientations):\n",
        "    truncation_distance = 2.5\n",
        "    truncation_value = get_lj_truncation_value(truncation_distance)\n",
        "\n",
        "    centroids_x = np.zeros((N * sample_its))\n",
        "    centroids_y = np.zeros((N * sample_its))\n",
        "    labels = np.arange(N * sample_its,\n",
        "                       dtype=np.int64)  # Set this to this since label is assumed to not matter for the moment\n",
        "    solutions = []  # solution structured as: [4-length np array for passive & active force, 4-length np array for passive & active force, ...]\n",
        "    frames = np.zeros((N * sample_its), dtype=np.int64)\n",
        "    for t in np.arange(sample_its, dtype=np.int64):\n",
        "        for i in range(N):\n",
        "            frames[i + t * N] = t\n",
        "    sets = np.zeros(N * sample_its, dtype=np.int64)\n",
        "\n",
        "    data_dict = {'label': labels, 'centroid-0': centroids_x, 'centroid-1': centroids_y, 'orientation': np.zeros((N * sample_its)),\n",
        "                 'solution': solutions, 'frame': frames, 'set': sets}\n",
        "\n",
        "    #coordinates, orientations = get_particles()\n",
        "    tic = time.time()\n",
        "    samp_i = 0\n",
        "    coordinates, orientations = get_particles()\n",
        "    for t in range(its):  \n",
        "        \n",
        "        if t in reset_indices:\n",
        "            coordinates, orientations = get_particles()\n",
        "        \n",
        "        coordinates, orientations, current_solutions = update_data(coordinates, orientations, potential_type, t, truncation_distance=truncation_distance, truncation_value=truncation_value)\n",
        "        \n",
        "        if t in sample_indices_vector:\n",
        "            data_dict['centroid-0'][N * samp_i: N + N * samp_i] = coordinates[:, 0]\n",
        "            data_dict['centroid-1'][N * samp_i: N + N * samp_i] = coordinates[:, 1]\n",
        "            data_dict['orientation'][N * samp_i: N + N * samp_i] = np.squeeze(orientations)\n",
        "            samp_i += 1\n",
        "            for i in range(N):\n",
        "                solutions.append(current_solutions[i])\n",
        "        \n",
        "        \n",
        "        if np.mod(t, its / 100) == 0:\n",
        "            toc = time.time()\n",
        "            T = (toc - tic)\n",
        "            print(str(int(t / its * 100)) + ' %, runtime: ' + str(T) + 's.')#, end='\\r')\n",
        "        \n",
        "\n",
        "        \n",
        "    toc = time.time()\n",
        "    T = (toc - tic) / its\n",
        "    print('Total runtime: ' + str(T * its)[:10] + ' s, (' + str(T)[:] + ' s per iteration)')\n",
        "    \n",
        "    if save:\n",
        "      import os\n",
        "      path = cur_path\n",
        "      parent_path = path.parent.absolute()\n",
        "      datasets_path = str(parent_path) + '/datasets/'\n",
        "      np.save(datasets_path + potential_type + '/N' + str(N) + ' samples' + str(\n",
        "          sample_its) + ' F_P' + str(F_P), {**data_dict,\n",
        "                                                          **{'box_len': box_len, 'interaction_radius': interaction_radius,\n",
        "                                                            'potential_type': potential_type}})\n",
        "\n",
        "    if plot:\n",
        "        color_v = plt.cm.brg(np.linspace(0, 1, N))\n",
        "        for i in range(N):\n",
        "            for t in range(sample_its):\n",
        "                if t == 0:\n",
        "                    plt.scatter(centroids_x[i + t * N], centroids_y[i + t * N], color=color_v[i], s=40, alpha=0.5,\n",
        "                                marker='*')\n",
        "                else:\n",
        "                    plt.scatter(centroids_x[i + t * N], centroids_y[i + t * N], color=color_v[i], s=4, alpha=0.5)\n",
        "\n",
        "                cir = plt.Circle((centroids_x[i + t * N], centroids_y[i + t * N]), 0.5, color='b', fill=False,\n",
        "                                 alpha=0.2)\n",
        "                ax = plt.gca()\n",
        "                ax.set_aspect('equal', adjustable='box')\n",
        "                ax.add_patch(cir)\n",
        "\n",
        "                plt.title(\"Scatter trajectories. Radius = \" + str(length_scale))\n",
        "                plt.xlim([-box_len / 2, box_len / 2])\n",
        "                plt.ylim([-box_len / 2, box_len / 2])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    if plot_last_frame:\n",
        "        fs = 5\n",
        "        fig_size = (fs, fs)\n",
        "        plt.figure(figsize=fig_size)\n",
        "        x_len = box_len\n",
        "        y_len = box_len\n",
        "        fig_to_window_fraction = 0.8\n",
        "        ax = plt.axes([0.1, 0.1, fig_to_window_fraction, fig_to_window_fraction], xlim=(-x_len / 2, x_len / 2), ylim=(-y_len / 2, y_len / 2))\n",
        "        box_len_ratio = x_len/box_len\n",
        "        radius_to_box_len = length_scale/box_len\n",
        "        radius_to_image = box_len_ratio * radius_to_box_len\n",
        "        points_per_inch = 72\n",
        "        points_whole_axis = fs * fig_to_window_fraction * points_per_inch # fs is in inches, s in points\n",
        "        points_radius = radius_to_image * points_whole_axis\n",
        "\n",
        "        for i in range(N):\n",
        "\n",
        "\n",
        "            plt.scatter(np.asnumpy(centroids_x[i + (sample_its-1) * N]), np.asnumpy(centroids_y[i + (sample_its-1) * N]), color=[1,0,0], s=5)#int(points_radius**2))\n",
        "\n",
        "        ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "\n",
        "        plt.title(\"Scatter trajectories. Radius = \" + str(length_scale))\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    return coordinates, orientations\n",
        "\n",
        "\n",
        "\n",
        "if profile:\n",
        "  cProfile.run('run(coordinates, orientations)', sort='cumtime')\n",
        "else:\n",
        "  coordinates, orientations = run(coordinates, orientations)"
      ],
      "metadata": {
        "id": "hf6pwibxczp_",
        "outputId": "35c085d1-bd86-4d78-d951-7e6610e34a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 %, runtime: 0.0030024051666259766s.\n",
            "1 %, runtime: 0.03197336196899414s.\n",
            "2 %, runtime: 0.06081843376159668s.\n",
            "3 %, runtime: 0.0904531478881836s.\n",
            "4 %, runtime: 0.12051606178283691s.\n",
            "5 %, runtime: 0.15031194686889648s.\n",
            "6 %, runtime: 0.1803145408630371s.\n",
            "7 %, runtime: 0.21391677856445312s.\n",
            "8 %, runtime: 0.2459573745727539s.\n",
            "9 %, runtime: 0.27825093269348145s.\n",
            "10 %, runtime: 0.3106191158294678s.\n",
            "11 %, runtime: 0.34253501892089844s.\n",
            "12 %, runtime: 0.3734550476074219s.\n",
            "13 %, runtime: 0.40468549728393555s.\n",
            "14 %, runtime: 0.4382288455963135s.\n",
            "15 %, runtime: 0.4697763919830322s.\n",
            "16 %, runtime: 0.5014791488647461s.\n",
            "17 %, runtime: 0.5334482192993164s.\n",
            "18 %, runtime: 0.5762302875518799s.\n",
            "19 %, runtime: 0.6153521537780762s.\n",
            "20 %, runtime: 0.6534128189086914s.\n",
            "21 %, runtime: 0.6867024898529053s.\n",
            "22 %, runtime: 0.7288386821746826s.\n",
            "23 %, runtime: 0.7730135917663574s.\n",
            "24 %, runtime: 0.8075108528137207s.\n",
            "25 %, runtime: 0.8418750762939453s.\n",
            "26 %, runtime: 0.8800866603851318s.\n",
            "27 %, runtime: 0.9173200130462646s.\n",
            "28 %, runtime: 0.9522154331207275s.\n",
            "28 %, runtime: 0.9867498874664307s.\n",
            "30 %, runtime: 1.0213568210601807s.\n",
            "31 %, runtime: 1.0628306865692139s.\n",
            "32 %, runtime: 1.1058802604675293s.\n",
            "33 %, runtime: 1.140594244003296s.\n",
            "34 %, runtime: 1.171299695968628s.\n",
            "35 %, runtime: 1.2003757953643799s.\n",
            "36 %, runtime: 1.2299904823303223s.\n",
            "37 %, runtime: 1.2709670066833496s.\n",
            "38 %, runtime: 1.3059189319610596s.\n",
            "39 %, runtime: 1.3393304347991943s.\n",
            "40 %, runtime: 1.3693816661834717s.\n",
            "41 %, runtime: 1.3992040157318115s.\n",
            "42 %, runtime: 1.4329471588134766s.\n",
            "43 %, runtime: 1.462937831878662s.\n",
            "44 %, runtime: 1.4931895732879639s.\n",
            "45 %, runtime: 1.5231666564941406s.\n",
            "46 %, runtime: 1.5566339492797852s.\n",
            "47 %, runtime: 1.5935869216918945s.\n",
            "48 %, runtime: 1.622887372970581s.\n",
            "49 %, runtime: 1.6520400047302246s.\n",
            "50 %, runtime: 1.6820573806762695s.\n",
            "51 %, runtime: 1.7131314277648926s.\n",
            "52 %, runtime: 1.7472844123840332s.\n",
            "53 %, runtime: 1.7891621589660645s.\n",
            "54 %, runtime: 1.8214998245239258s.\n",
            "55 %, runtime: 1.8608386516571045s.\n",
            "56 %, runtime: 1.9015083312988281s.\n",
            "56 %, runtime: 1.9324281215667725s.\n",
            "57 %, runtime: 1.9630305767059326s.\n",
            "59 %, runtime: 1.9982035160064697s.\n",
            "60 %, runtime: 2.028416633605957s.\n",
            "61 %, runtime: 2.0608129501342773s.\n",
            "62 %, runtime: 2.089776039123535s.\n",
            "63 %, runtime: 2.1187665462493896s.\n",
            "64 %, runtime: 2.148872137069702s.\n",
            "65 %, runtime: 2.1788246631622314s.\n",
            "66 %, runtime: 2.2188830375671387s.\n",
            "67 %, runtime: 2.2516896724700928s.\n",
            "68 %, runtime: 2.283212900161743s.\n",
            "69 %, runtime: 2.3138623237609863s.\n",
            "70 %, runtime: 2.3457207679748535s.\n",
            "71 %, runtime: 2.3767545223236084s.\n",
            "72 %, runtime: 2.4065768718719482s.\n",
            "73 %, runtime: 2.438758373260498s.\n",
            "74 %, runtime: 2.471270799636841s.\n",
            "75 %, runtime: 2.499582052230835s.\n",
            "76 %, runtime: 2.528334856033325s.\n",
            "77 %, runtime: 2.557771682739258s.\n",
            "78 %, runtime: 2.596721649169922s.\n",
            "79 %, runtime: 2.629319190979004s.\n",
            "80 %, runtime: 2.6623458862304688s.\n",
            "81 %, runtime: 2.693443775177002s.\n",
            "82 %, runtime: 2.7245595455169678s.\n",
            "83 %, runtime: 2.757045269012451s.\n",
            "84 %, runtime: 2.7963337898254395s.\n",
            "85 %, runtime: 2.829883098602295s.\n",
            "86 %, runtime: 2.8603198528289795s.\n",
            "87 %, runtime: 2.8942301273345947s.\n",
            "88 %, runtime: 2.9282915592193604s.\n",
            "89 %, runtime: 2.9611093997955322s.\n",
            "90 %, runtime: 2.991379737854004s.\n",
            "91 %, runtime: 3.0224153995513916s.\n",
            "92 %, runtime: 3.053328275680542s.\n",
            "93 %, runtime: 3.084920644760132s.\n",
            "94 %, runtime: 3.120418071746826s.\n",
            "95 %, runtime: 3.1518146991729736s.\n",
            "96 %, runtime: 3.186998128890991s.\n",
            "97 %, runtime: 3.2176427841186523s.\n",
            "98 %, runtime: 3.252629041671753s.\n",
            "99 %, runtime: 3.2833850383758545s.\n",
            "Total runtime: 3.31267499 s, (0.0033126749992370605 s per iteration)\n",
            "         317158 function calls in 3.315 seconds\n",
            "\n",
            "   Ordered by: cumulative time\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        1    0.000    0.000    3.315    3.315 {built-in method builtins.exec}\n",
            "        1    0.000    0.000    3.315    3.315 <string>:1(<module>)\n",
            "        1    0.462    0.462    3.315    3.315 <ipython-input-53-53aabe029dd4>:319(run)\n",
            "     1000    0.537    0.001    2.792    0.003 <ipython-input-53-53aabe029dd4>:274(update_data)\n",
            "     1000    0.002    0.000    1.031    0.001 <ipython-input-53-53aabe029dd4>:206(Mget_potential_gradients)\n",
            "     1000    0.009    0.000    1.029    0.001 <ipython-input-53-53aabe029dd4>:151(Mget_tslj_potential_gradient)\n",
            "     1000    0.246    0.000    1.020    0.001 <ipython-input-53-53aabe029dd4>:128(Mget_lj_potential_gradient)\n",
            "     1000    0.348    0.000    0.671    0.001 <ipython-input-53-53aabe029dd4>:54(get_min_dist_vectors_mtx)\n",
            "     2000    0.417    0.000    0.452    0.000 <ipython-input-53-53aabe029dd4>:112(Mget_lj_potential)\n",
            "     3000    0.008    0.000    0.250    0.000 join.py:122(stack)\n",
            "     4000    0.004    0.000    0.239    0.000 join.py:35(concatenate)\n",
            "     4000    0.235    0.000    0.235    0.000 {built-in method cupy._core._routines_manipulation.concatenate_method}\n",
            "     4000    0.091    0.000    0.215    0.000 search.py:177(where)\n",
            "     1000    0.130    0.000    0.191    0.000 <ipython-input-53-53aabe029dd4>:233(Mget_velocity_separated)\n",
            "     2000    0.014    0.000    0.139    0.000 insert.py:142(fill_diagonal)\n",
            "    30035    0.034    0.000    0.130    0.000 <__array_function__ internals>:177(min_scalar_type)\n",
            "     2000    0.051    0.000    0.124    0.000 iterate.py:33(__setitem__)\n",
            "     4000    0.104    0.000    0.121    0.000 {method 'astype' of 'cupy._core.core._ndarray_base' objects}\n",
            "    40043    0.114    0.000    0.114    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
            "     2000    0.004    0.000    0.111    0.000 sumprod.py:9(sum)\n",
            "     2000    0.106    0.000    0.106    0.000 {method 'sum' of 'cupy._core.core._ndarray_base' objects}\n",
            "     1000    0.035    0.000    0.093    0.000 <ipython-input-53-53aabe029dd4>:65(v_mtx_to_d_mtx)\n",
            "     2000    0.077    0.000    0.086    0.000 {method 'copy' of 'cupy._core.core._ndarray_base' objects}\n",
            "     2000    0.005    0.000    0.082    0.000 _sample.py:47(randn)\n",
            "     2000    0.004    0.000    0.077    0.000 _distributions.py:482(normal)\n",
            "     2000    0.005    0.000    0.069    0.000 _generator.py:439(normal)\n",
            "     2000    0.002    0.000    0.065    0.000 from_data.py:49(asarray)\n",
            "     2000    0.057    0.000    0.063    0.000 {built-in method cupy._core.core.array}\n",
            "     2000    0.018    0.000    0.060    0.000 _generator.py:71(_generate_normal)\n",
            "     3000    0.006    0.000    0.059    0.000 join.py:135(<listcomp>)\n",
            "     6000    0.006    0.000    0.053    0.000 dims.py:132(expand_dims)\n",
            "     6000    0.027    0.000    0.047    0.000 {built-in method cupy._core._routines_manipulation._expand_dims}\n",
            "    10008    0.013    0.000    0.041    0.000 <__array_function__ internals>:177(can_cast)\n",
            "    22026    0.021    0.000    0.040    0.000 numeric.py:1859(isscalar)\n",
            "    40228    0.013    0.000    0.021    0.000 {built-in method builtins.isinstance}\n",
            "     2000    0.017    0.000    0.017    0.000 {built-in method cupy_backends.cuda.libs.curand.generateNormalDouble}\n",
            "     2002    0.017    0.000    0.017    0.000 basic.py:7(empty)\n",
            "      101    0.001    0.000    0.015    0.000 {built-in method builtins.print}\n",
            "      202    0.001    0.000    0.014    0.000 iostream.py:384(write)\n",
            "      217    0.001    0.000    0.012    0.000 iostream.py:195(schedule)\n",
            "     4995    0.012    0.000    0.012    0.000 _internal.py:250(__init__)\n",
            "      217    0.009    0.000    0.009    0.000 socket.py:543(send)\n",
            "     8000    0.003    0.000    0.008    0.000 abc.py:117(__instancecheck__)\n",
            "    30035    0.008    0.000    0.008    0.000 multiarray.py:613(min_scalar_type)\n",
            "     4995    0.004    0.000    0.007    0.000 syncdetect.py:36(_declare_synchronize)\n",
            "     8000    0.005    0.000    0.005    0.000 {built-in method _abc._abc_instancecheck}\n",
            "     2000    0.004    0.000    0.005    0.000 _generator.py:1199(get_random_state)\n",
            "     1000    0.004    0.000    0.004    0.000 {method 'reshape' of 'cupy._core.core._ndarray_base' objects}\n",
            "     6000    0.003    0.000    0.003    0.000 {built-in method cupy._core._fusion_thread_local.is_fusing}\n",
            "     4995    0.003    0.000    0.003    0.000 syncdetect.py:27(_is_allowed)\n",
            "     2000    0.003    0.000    0.003    0.000 _generator.py:1235(_check_and_get_dtype)\n",
            "    10008    0.002    0.000    0.002    0.000 multiarray.py:498(can_cast)\n",
            "     2000    0.002    0.000    0.002    0.000 {built-in method cupy._core.internal.complete_slice}\n",
            "     4995    0.002    0.000    0.002    0.000 _internal.py:304(data)\n",
            "     2000    0.002    0.000    0.002    0.000 {built-in method cupy._core.internal.get_size}\n",
            "     2000    0.002    0.000    0.002    0.000 iterate.py:29(__init__)\n",
            "     2000    0.001    0.000    0.001    0.000 {built-in method cupy._core.internal.prod}\n",
            "      217    0.001    0.000    0.001    0.000 threading.py:1169(is_alive)\n",
            "     4000    0.001    0.000    0.001    0.000 {method 'count' of 'tuple' objects}\n",
            "      202    0.000    0.000    0.001    0.000 iostream.py:308(_is_master_process)\n",
            "      217    0.000    0.000    0.001    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
            "     2000    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
            "     2000    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
            "      202    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
            "      202    0.000    0.000    0.000    0.000 iostream.py:321(_schedule_flush)\n",
            "      217    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
            "      217    0.000    0.000    0.000    0.000 iostream.py:91(_event_pipe)\n",
            "        1    0.000    0.000    0.000    0.000 <ipython-input-53-53aabe029dd4>:102(get_lj_truncation_value)\n",
            "        1    0.000    0.000    0.000    0.000 <ipython-input-53-53aabe029dd4>:106(get_lj_potential)\n",
            "      217    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
            "      102    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
            "        2    0.000    0.000    0.000    0.000 ranges.py:9(arange)\n",
            "      217    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
            "        5    0.000    0.000    0.000    0.000 basic.py:196(zeros)\n",
            "        5    0.000    0.000    0.000    0.000 {method 'memset_async' of 'cupy.cuda.memory.MemoryPointer' objects}\n",
            "        4    0.000    0.000    0.000    0.000 dims.py:151(squeeze)\n",
            "        4    0.000    0.000    0.000    0.000 {method 'squeeze' of 'cupy._core.core._ndarray_base' objects}\n",
            "       20    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yaI7fC0yMMJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Colab* git actions"
      ],
      "metadata": {
        "id": "pRxApdSqWs4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/exjobb\n",
        "!git status"
      ],
      "metadata": {
        "id": "ZUKmBi4IDmSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80ce057-b0a6-4f4f-ad25-866043d6ba64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/exjobb\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   miguel/datasets/tslj/N5 samples100 F_P60.npy\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmiguel/datasets/tslj/N100 samples100 F_P60.npy\u001b[m\n",
            "\t\u001b[31mmiguel/datasets/tslj/N1005 samples100 F_P60.npy\u001b[m\n",
            "\t\u001b[31mmiguel/datasets/tslj/N50 samples100 F_P60.npy\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "uD2_V9kBaYQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add miguel/datasets/tslj/N5\\ samples1000\\ F_P60.npy"
      ],
      "metadata": {
        "id": "gZZWuQmVkGhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Data after simulation periodic boundary fix\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vF-H0HpXXKi",
        "outputId": "f3588aaf-ade9-49e7-d107-23d9573e25ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 141f610] Data after simulation periodic boundary fix\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 miguel/datasets/tslj/N5 samples1000 F_P60.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remember to create new token for each use\n",
        "!git push https://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@github.com/Phistian/exjobb.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLdczHb-XWuN",
        "outputId": "93f91a70-98b6-447b-fecb-37f123cf1d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 10, done.\n",
            "Counting objects:  10% (1/10)\rCounting objects:  20% (2/10)\rCounting objects:  30% (3/10)\rCounting objects:  40% (4/10)\rCounting objects:  50% (5/10)\rCounting objects:  60% (6/10)\rCounting objects:  70% (7/10)\rCounting objects:  80% (8/10)\rCounting objects:  90% (9/10)\rCounting objects: 100% (10/10)\rCounting objects: 100% (10/10), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  16% (1/6)\rCompressing objects:  33% (2/6)\rCompressing objects:  50% (3/6)\rCompressing objects:  66% (4/6)\rCompressing objects:  83% (5/6)\rCompressing objects: 100% (6/6)\rCompressing objects: 100% (6/6), done.\n",
            "Writing objects:  16% (1/6)\rWriting objects:  33% (2/6)\rWriting objects:  50% (3/6)\rWriting objects:  66% (4/6)\rWriting objects:  83% (5/6)\rWriting objects: 100% (6/6)\rWriting objects: 100% (6/6), 356.97 KiB | 7.14 MiB/s, done.\n",
            "Total 6 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas:   0% (0/4)\u001b[K\rremote: Resolving deltas:  25% (1/4)\u001b[K\rremote: Resolving deltas:  50% (2/4)\u001b[K\rremote: Resolving deltas:  75% (3/4)\u001b[K\rremote: Resolving deltas: 100% (4/4)\u001b[K\rremote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/Phistian/exjobb.git\n",
            "   a70287f..141f610  main -> main\n"
          ]
        }
      ]
    }
  ]
}