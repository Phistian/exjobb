{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz5PzP/f7TC5PcIR7sUyi7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phistian/exjobb/blob/main/miguel/simulations/fast_standard_simulation_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "  !git clone https://github.com/Phistian/exjobb\n",
        "  !git config --global user.email \"christianrut42@gmail.com\"\n",
        "  !git config --global user.name \"Phistian\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  cur_path = Path(\"/content/exjobb/miguel/simulations\")\n",
        "else:\n",
        "  cur_path = Path(__file__)\n",
        "\n",
        "\n",
        "parent_path = cur_path.parent.resolve()\n",
        "exjobb_address = str(parent_path) + \"/../\"\n",
        "spatial_address = str(parent_path) + '/spatial_gnns/'\n",
        "datasets_address = str(parent_path) + '/datasets/'\n",
        "histories_address = str(parent_path) + '/training_results/saved_histories/'\n",
        "models_address = str(parent_path) + '/training_results/saved_models/'\n",
        "sys.path.append(spatial_address)\n",
        "sys.path.append(str(parent_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORv9B-6dieu7",
        "outputId": "0db841c1-d4b3-4e68-c557-e4d530938073"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'exjobb' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uTNpTb0hNR8",
        "outputId": "3750e86f-48c7-432e-db78-628ba0db86d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-c8ed05eadfd7>:122: RuntimeWarning: invalid value encountered in true_divide\n",
            "  gradients = gradient_magnitudes * -S / Dstacked  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total runtime: 21.1773512 s, (0.0021177351236343384 s per iteration)\n",
            "[60.         60.         78.01241569 82.51148067]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "from pathlib import Path\n",
        "import matplotlib.cm as cm\n",
        "import cProfile\n",
        "import re\n",
        "\n",
        "##INFO\n",
        "\n",
        "##PARAMETERS\n",
        "rho = 0.2  # total particle area to box_area ratio  ρ ∈ {0.1, 0.2}\n",
        "F_P = 60\n",
        "N = 100  # for its= 1e2, sample_its = 100: 50 11, 100 46\n",
        "its = int(1e4)  # 1e5\n",
        "sample_its = 100\n",
        "n_resets = 0  # including first run\n",
        "interact_across_borders = True\n",
        "potential_type = 'tslj'\n",
        "plot = False\n",
        "\n",
        "##VARIABLES AND CONSTANTS\n",
        "its_per_reset = int(its / (n_resets + 1))\n",
        "reset_indices = np.linspace(its_per_reset, its - its_per_reset, n_resets, dtype=int)\n",
        "sample_indices_vector = np.linspace(0, its - 1, sample_its, dtype=int)\n",
        "boltzmann = 1\n",
        "energy_parameter = 1\n",
        "# temperature = 0.01\n",
        "diffusion_translational = 0.01\n",
        "diffusion_rotational = 1  # Dr ∈ {0.25, 1.0}\n",
        "dt = 1e-5\n",
        "length_scale = 1\n",
        "interaction_radius = 3 * length_scale\n",
        "duplicate_search_threshold = interaction_radius\n",
        "dx = length_scale / 10000\n",
        "\n",
        "one_particle_area = (length_scale / 2) ** 2 * np.pi\n",
        "box_area = N * one_particle_area / rho\n",
        "box_len = np.sqrt(box_area)\n",
        "if box_len < duplicate_search_threshold:\n",
        "    raise Exception(\"The box length is very small in comparison to the interaction radius\")\n",
        "\n",
        "ADDITIONS = [np.array([0, 0]), np.array([box_len, 0]), np.array([-box_len, 0]), np.array([0, box_len]),\n",
        "             np.array([0, -box_len]), np.array([box_len, box_len]), np.array([-box_len, box_len]),\n",
        "             np.array([box_len, -box_len]), np.array([-box_len, -box_len])]\n",
        "\n",
        "\n",
        "def get_min_dist_vectors_mtx(coords):\n",
        "    dx = np.subtract.outer(coords[:, 0], coords[:, 0])\n",
        "    dx = np.where(dx > 0.5*box_len, dx - box_len, np.where(dx < -0.5*box_len, dx + box_len, dx))\n",
        "    dy = np.subtract.outer(coords[:, 1], coords[:, 1])\n",
        "    dy = np.where(dy > 0.5 * box_len, dy - box_len, np.where(dy < -0.5 * box_len, dy + box_len, dy))\n",
        "    dist_min = np.stack((dx, dy), axis=0)\n",
        "    return dist_min\n",
        "\n",
        "def v_mtx_to_d_mtx(v_mtx):\n",
        "    sq_v = np.square(v_mtx)\n",
        "    sq_d = np.sum(sq_v, axis=0)\n",
        "    d = np.sqrt(sq_d)\n",
        "    return d\n",
        "\n",
        "def get_distance_matrix(coords):\n",
        "    d = v_mtx_to_d_mtx(get_min_dist_vectors_mtx(coords))\n",
        "    return d\n",
        "\n",
        "def get_distances_until_chosen_particle(chosen_particle, coords):\n",
        "    dx = np.subtract.outer(coords[chosen_particle, 0], coords[:chosen_particle, 0])\n",
        "    dx = np.where(dx > 0.5 * box_len, dx - box_len, np.where(dx < -0.5 * box_len, dx + box_len, dx))\n",
        "    dy = np.subtract.outer(coords[chosen_particle, 1], coords[:chosen_particle, 1])\n",
        "    dy = np.where(dy > 0.5 * box_len, dy - box_len, np.where(dy < -0.5 * box_len, dy + box_len, dy))\n",
        "    dist = np.sqrt(dx**2 + dy**2)\n",
        "    return dist\n",
        "\n",
        "def get_particles(n_particles=N):\n",
        "    coordinates = np.random.uniform(-box_len / 2, box_len / 2, size=(n_particles, 2))\n",
        "    collision_present = True\n",
        "\n",
        "    for i in range(1, n_particles):\n",
        "        D = get_distances_until_chosen_particle(i, coordinates)\n",
        "        threshold = length_scale * 1.1\n",
        "        collision_mtx = np.where(D < threshold, 1, 0)\n",
        "        while collision_mtx.any():\n",
        "            coordinates[i, :] = np.random.uniform(-box_len / 2, box_len / 2, 2)\n",
        "            D = get_distances_until_chosen_particle(i, coordinates)\n",
        "            collision_mtx = np.where(D < threshold, 1, 0)\n",
        "    orientations = np.random.uniform(low=0, high=2 * np.pi, size=(n_particles, 1))\n",
        "    return coordinates, orientations\n",
        "\n",
        "\n",
        "##POTENTIALS AND THEIR GRADIENTS - FUNCTIONS\n",
        "def get_lj_truncation_value(truncation_distance):\n",
        "    return get_lj_potential(truncation_distance)\n",
        "\n",
        "\n",
        "def get_lj_potential(distance, truncation_distance=box_len, truncation_value=0):\n",
        "    if distance < truncation_distance:\n",
        "        potential = 4 * energy_parameter * ((1 / distance) ** 12 - (1 / distance) ** 6) - truncation_value\n",
        "    else:\n",
        "        potential = 0\n",
        "    return potential\n",
        "def Mget_lj_potential(D, truncation_distance=box_len, truncation_value=0):\n",
        "    potentials = np.where(D < truncation_distance, 4 * energy_parameter * ((1 / D) ** 12 - (1 / D) ** 6) - truncation_value, 0)\n",
        "    return potentials\n",
        "\n",
        "\n",
        "def get_lj_potential_gradient(distance_vector, truncation_distance, truncation_value):\n",
        "    distance = np.sqrt(distance_vector.dot(distance_vector))\n",
        "    difference = get_lj_potential(distance + dx, truncation_distance, truncation_value) - get_lj_potential(\n",
        "        distance - dx, truncation_distance, truncation_value)\n",
        "    gradient_magnitude = difference / (2 * dx)\n",
        "    gradient = gradient_magnitude * -distance_vector / distance  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    return gradient\n",
        "def Mget_lj_potential_gradient(S, D, truncation_distance, truncation_value):\n",
        "    differences = Mget_lj_potential(D + dx, truncation_distance, truncation_value) - Mget_lj_potential(\n",
        "        D - dx, truncation_distance, truncation_value)\n",
        "    gradient_magnitudes = differences / (2 * dx)\n",
        "    gradient_magnitudes = np.stack((gradient_magnitudes, gradient_magnitudes), axis=0)\n",
        "    Dstacked = np.stack((D,D), axis=0)\n",
        "    gradients = gradient_magnitudes * -S / Dstacked  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    np.fill_diagonal(gradients[0,:,:], 0)\n",
        "    np.fill_diagonal(gradients[1, :, :], 0)\n",
        "    return gradients\n",
        "\n",
        "\n",
        "def get_tslj_potential(distance):\n",
        "    return get_lj_potential(distance, truncation_distance=2.5, truncation_value=get_lj_truncation_value(2.5))\n",
        "\n",
        "\n",
        "def get_tslj_potential_gradient(distance_vector):\n",
        "    return get_lj_potential_gradient(distance_vector, truncation_distance=2.5,\n",
        "                                     truncation_value=get_lj_truncation_value(2.5))\n",
        "def Mget_tslj_potential_gradient(S, D):\n",
        "    return Mget_lj_potential_gradient(S, D, truncation_distance=2.5,\n",
        "                                     truncation_value=get_lj_truncation_value(2.5))\n",
        "\n",
        "\n",
        "def get_wca_potential(distance):\n",
        "    r_cut = length_scale * (2 ** (1 / 6))\n",
        "    return get_lj_potential(distance, truncation_distance=r_cut, truncation_value=get_lj_truncation_value(r_cut))\n",
        "\n",
        "\n",
        "def get_wca_potential_gradient(distance_vector):\n",
        "    r_cut = length_scale * 2 ** (1 / 6)\n",
        "    return get_lj_potential_gradient(distance_vector, truncation_distance=r_cut,\n",
        "                                     truncation_value=get_lj_truncation_value(r_cut))\n",
        "def Mget_wca_potential_gradient(S, D):\n",
        "    r_cut = length_scale * 2 ** (1 / 6)\n",
        "    return Mget_lj_potential_gradient(S, D, truncation_distance=r_cut,\n",
        "                                     truncation_value=get_lj_truncation_value(r_cut))\n",
        "\n",
        "\n",
        "def get_srs_potential(r, n=14, k0=10 / length_scale, eps_s=1, sig_s=2.5):\n",
        "    return energy_parameter * (length_scale / r) ** n + 1 / 2 * eps_s * (1 - np.tanh(k0 * (r - sig_s)))\n",
        "\n",
        "\n",
        "def get_srs_potential_gradient(distance_vector):\n",
        "    distance = np.sqrt(distance_vector.dot(distance_vector))\n",
        "    difference = get_srs_potential(distance + dx) - get_srs_potential(distance - dx)\n",
        "    gradient_magnitude = difference / (2 * dx)\n",
        "    gradient = gradient_magnitude * -distance_vector / distance  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    return gradient\n",
        "def Mget_srs_potential_gradient(S, D): ##TODO FINISH THIS\n",
        "    distance = np.sqrt(S.dot(S))\n",
        "    difference = get_srs_potential(distance + dx) - get_srs_potential(distance - dx)\n",
        "    gradient_magnitude = difference / (2 * dx)\n",
        "    gradient = gradient_magnitude * -S / distance  # minus the distance vector since this gives the correct force directions w.r.t. potential gradient sign\n",
        "    return gradient\n",
        "\n",
        "\n",
        "def get_potential(distance, key):\n",
        "    if key == 'tslj':\n",
        "        return get_tslj_potential(distance)\n",
        "    elif key == 'wca':\n",
        "        return get_wca_potential(distance)\n",
        "    elif key == 'srs':\n",
        "        return get_srs_potential(distance)\n",
        "\n",
        "\n",
        "def get_potential_gradient(distance_vector, key):\n",
        "    if key == 'tslj':\n",
        "        return get_tslj_potential_gradient(distance_vector)\n",
        "    elif key == 'wca':\n",
        "        return get_wca_potential_gradient(distance_vector)\n",
        "    elif key == 'srs':\n",
        "        return get_srs_potential_gradient(distance_vector)\n",
        "\n",
        "def Mget_potential_gradients(S, D, key):\n",
        "    if key == 'tslj':\n",
        "        return Mget_tslj_potential_gradient(S, D)\n",
        "    elif key == 'wca':\n",
        "        return Mget_wca_potential_gradient(S, D)\n",
        "    elif key == 'srs':\n",
        "        return Mget_srs_potential_gradient(S, D)\n",
        "\n",
        "    ##GET INFO - FUNCTIONS\n",
        "\n",
        "\n",
        "def get_velocity(orientation, f_p, summed_gradients_vector):\n",
        "    # thermal_force = np.sqrt(2*diffusion_translational) * np.random.randn(2)  #~0.1\n",
        "    active_force = np.squeeze(np.array([np.cos(orientation), np.sin(orientation)]) * f_p)  # ~0.3\n",
        "    passive_force = -summed_gradients_vector  # diffusion_translational * -summed_gradients_vector  #varies based on density\n",
        "    # print(passive_force)\n",
        "\n",
        "    return active_force + passive_force\n",
        "\n",
        "\n",
        "def get_velocity_separated(orientation, f_p, summed_gradients_vector):\n",
        "    # thermal_force = np.sqrt(2*diffusion_translational) * np.random.randn(2)  #~0.1\n",
        "    active_force = np.squeeze(np.array([np.cos(orientation), np.sin(orientation)]) * f_p)  # ~0.3\n",
        "    passive_force = -summed_gradients_vector  # varies based on density\n",
        "    # print(passive_force)\n",
        "\n",
        "    return active_force + passive_force, active_force, passive_force\n",
        "def Mget_velocity_separated(orientations, f_p, summed_gradients):\n",
        "    cospart = np.cos(orientations)\n",
        "    sinpart = np.sin(orientations)\n",
        "    active_force = np.concatenate((cospart, sinpart), axis=1) * f_p  # ~0.3\n",
        "\n",
        "\n",
        "    passive_force = -summed_gradients  # varies based on density\n",
        "    # print(passive_force)\n",
        "\n",
        "    return active_force + passive_force, active_force, passive_force\n",
        "\n",
        "\n",
        "def get_energies(coordinates, orientations, velocities, truncation_distance, truncation_value, t):  # OLD AND UNUSED\n",
        "    n_particles = coordinates.shape[0]\n",
        "    new_coordinates = coordinates\n",
        "    new_orientations = orientations\n",
        "    saved_distances = np.zeros(shape=(n_particles, n_particles, 2))\n",
        "    kinetic_energy = 0\n",
        "    potential_energy = 0\n",
        "\n",
        "    for i, pos0 in enumerate(coordinates):\n",
        "        gradients_sum = np.zeros(2)\n",
        "        for j, pos1 in enumerate(coordinates):\n",
        "            d_v = pos1 - pos0\n",
        "            saved_distances[i, j, :] = d_v\n",
        "            if d_v[0] < duplicate_search_threshold and d_v[1] < duplicate_search_threshold and i != j:\n",
        "                gradients_sum += get_lj_potential_gradient(d_v, truncation_distance, truncation_value)\n",
        "            if i != j:\n",
        "                d = np.sqrt(d_v.dot(d_v))\n",
        "                potential_energy += get_lj_potential(d, truncation_distance, truncation_value)\n",
        "\n",
        "        velocity = get_velocity(orientations[i], F_P, gradients_sum)\n",
        "        kinetic_energy += velocity.dot(velocity)  # m = 1\n",
        "    kinetic_energy = kinetic_energy / 2\n",
        "    potential_energy = potential_energy / 2\n",
        "    total_energy = kinetic_energy + potential_energy\n",
        "\n",
        "    return kinetic_energy, potential_energy, total_energy\n",
        "\n",
        "\n",
        "##UPDATING - FUNCTIONS\n",
        "def update_data(coordinates, orientations, full_data_dict, potential_key, t):\n",
        "    full_data_dict['centroid-0'][N * t: N + N * t] = coordinates[:, 0]\n",
        "    full_data_dict['centroid-1'][N * t: N + N * t] = coordinates[:, 1]\n",
        "    full_data_dict['orientation'][N * t: N + N * t] = np.squeeze(orientations)\n",
        "\n",
        "    new_coordinates = coordinates.copy()\n",
        "    new_orientations = orientations.copy()\n",
        "    new_coordinates2 = coordinates.copy()\n",
        "    new_orientations2 = orientations.copy()\n",
        "\n",
        "    S = -get_min_dist_vectors_mtx(coordinates)\n",
        "    D = v_mtx_to_d_mtx(S)\n",
        "    gradients = Mget_potential_gradients(S, D, potential_key)\n",
        "    gradient_sums = np.sum(gradients, axis=-1)\n",
        "    gradient_sums = gradient_sums.T\n",
        "    v, active_v, passive_v = Mget_velocity_separated(orientations, F_P, gradient_sums)\n",
        "    if D[0,1]<0.9:\n",
        "        print(\"hmm\")\n",
        "    angular_diffusion_steps = np.sqrt(2 * diffusion_rotational * dt) * np.random.randn(N, 1)\n",
        "    diffusion_steps = np.sqrt(dt * diffusion_translational * 2) * np.random.randn(N, 2)\n",
        "    new_coordinates += dt * v + diffusion_steps\n",
        "    new_orientations += angular_diffusion_steps\n",
        "\n",
        "    new_coordinates_x = new_coordinates[:, 0]\n",
        "    new_coordinates_y = new_coordinates[:, 1]\n",
        "    new_coordinates_x = np.where(new_coordinates_x > 0.5 * box_len, new_coordinates_x - box_len,\n",
        "                                 np.where(new_coordinates_x < -0.5 * box_len, new_coordinates_x + box_len, new_coordinates_x))\n",
        "    new_coordinates_y = np.where(new_coordinates_y > 0.5 * box_len, new_coordinates_y - box_len,\n",
        "                                 np.where(new_coordinates_y < -0.5 * box_len, new_coordinates_y + box_len, new_coordinates_y))\n",
        "    new_coordinates[:, 0] = new_coordinates_x\n",
        "    new_coordinates[:, 1] = new_coordinates_y\n",
        "\n",
        "    new_orientations = np.where(new_orientations > np.pi * 2, new_orientations - np.pi * 2,\n",
        "                               np.where(new_orientations < 0, new_orientations + np.pi * 2, new_orientations))\n",
        "\n",
        "\n",
        "    new_solutions = np.concatenate((active_v, passive_v), axis=1)\n",
        "    full_data_dict['solution'][t*N:t*N + N, :] = new_solutions  # check if size correct\n",
        "\n",
        "    return new_coordinates, new_orientations\n",
        "\n",
        "\n",
        "##SIMULATION\n",
        "## Arrays to save stuff into\n",
        "\n",
        "\n",
        "\n",
        "centroids_x = np.zeros((N * sample_its))\n",
        "centroids_y = np.zeros((N * sample_its))\n",
        "orientations = np.zeros((N * sample_its))\n",
        "labels = np.arange(N * sample_its,\n",
        "                   dtype=np.int64)  # Set this to this since label is assumed to not matter for the moment\n",
        "solutions = []  # solution structured as: [4-length np array for passive & active force, 4-length np array for passive & active force, ...]\n",
        "frames = np.zeros((N * sample_its), dtype=np.int64)\n",
        "for t in np.arange(sample_its, dtype=np.int64):\n",
        "    for i in range(N):\n",
        "        frames[i + t * N] = t\n",
        "sets = np.zeros(N * sample_its, dtype=np.int64)\n",
        "# print(frames)\n",
        "data_dict = {'label': labels, 'centroid-0': centroids_x, 'centroid-1': centroids_y, 'orientation': orientations,\n",
        "             'solution': solutions, 'frame': frames, 'set': sets}\n",
        "\n",
        "all_centroids_x = np.zeros((N * its))\n",
        "all_centroids_y = np.zeros((N * its))\n",
        "all_orientations = np.zeros((N * its))\n",
        "all_solutions = np.zeros((N * its, 4))\n",
        "full_data_dict = {'centroid-0': all_centroids_x, 'centroid-1': all_centroids_y, 'orientation': all_orientations,\n",
        "                  'solution': all_solutions}\n",
        "\n",
        "coordinates, orientations = get_particles()\n",
        "tic = time.time()\n",
        "for t in range(its):\n",
        "    if t in reset_indices:\n",
        "        coordinates, orientations = get_particles()\n",
        "    coordinates, orientations = update_data(coordinates, orientations, full_data_dict, potential_type, t)\n",
        "    if not np.mod(t, its / 100):\n",
        "        toc = time.time()\n",
        "        T = (toc - tic)\n",
        "        print(str(int(t / its * 100)) + ' %, runtime: ' + str(T) + 's.', end='\\r')\n",
        "for st, t in enumerate(sample_indices_vector):\n",
        "    data_dict['centroid-0'][N * st: N + N * st] = all_centroids_x[N * t: N + N * t]\n",
        "    data_dict['centroid-1'][N * st: N + N * st] = all_centroids_y[N * t: N + N * t]\n",
        "    data_dict['orientation'][N * st: N + N * st] = all_orientations[N * t: N + N * t]\n",
        "    for i in range(N):\n",
        "        solutions.append(all_solutions[\n",
        "                             i + N * t])  # I found this structure to be a way to make vector input to one column in pandas work\n",
        "toc = time.time()\n",
        "T = (toc - tic) / its\n",
        "print('Total runtime: ' + str(T * its)[:10] + ' s, (' + str(T)[:] + ' s per iteration)')\n",
        "\n",
        "##SAVING DATA\n",
        "import os\n",
        "\n",
        "path = cur_path\n",
        "parent_path = path.parent.absolute()\n",
        "datasets_path = str(parent_path) + '/datasets/'\n",
        "np.save(datasets_path + potential_type + '/N' + str(N) + ' samples' + str(\n",
        "    sample_its) + ' F_P' + str(F_P), {**data_dict,\n",
        "                                                    **{'box_len': box_len, 'interaction_radius': interaction_radius,\n",
        "                                                       'potential_type': potential_type}})\n",
        "# Finding max\n",
        "maxima = np.zeros(4)\n",
        "for i in range(len(all_solutions)):\n",
        "    for j in range(4):\n",
        "        if maxima[j] < np.abs(all_solutions[i][j]):\n",
        "            maxima[j] = abs(all_solutions[i][j])\n",
        "            if maxima[j] > 300:\n",
        "                print(i)\n",
        "\n",
        "print(maxima)\n",
        "##PLOTS\n",
        "\n",
        "if plot:\n",
        "    color_v = plt.cm.brg(np.linspace(0, 1, N))\n",
        "    for i in range(N):\n",
        "        for t in range(0, its, int(its / 40)):\n",
        "            if t == 0:\n",
        "                plt.scatter(all_centroids_x[i + t * N], all_centroids_y[i + t * N], color=color_v[i], s=40, alpha=0.5,\n",
        "                            marker='*')\n",
        "            else:\n",
        "                plt.scatter(all_centroids_x[i + t * N], all_centroids_y[i + t * N], color=color_v[i], s=4, alpha=0.5)\n",
        "\n",
        "            cir = plt.Circle((all_centroids_x[i + t * N], all_centroids_y[i + t * N]), 0.5, color='b', fill=False,\n",
        "                             alpha=0.2)\n",
        "            ax = plt.gca()\n",
        "            ax.set_aspect('equal', adjustable='box')\n",
        "            ax.add_patch(cir)\n",
        "\n",
        "            plt.title(\"Scatter trajectories. Radius = \" + str(length_scale))\n",
        "            plt.xlim([-box_len / 2, box_len / 2])\n",
        "            plt.ylim([-box_len / 2, box_len / 2])\n",
        "\n",
        "    plt.show()\n",
        "#cProfile.run('ey()', sort='cumtime')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_centroids_x[::5]"
      ],
      "metadata": {
        "id": "LGuNJyHcrLvw",
        "outputId": "e961d34d-f68a-40d7-9b74-9875856809df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.38748041, 0.38748041, 0.38748041, ..., 0.38748041, 0.38748041,\n",
              "       0.38748041])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Colab* git actions"
      ],
      "metadata": {
        "id": "pRxApdSqWs4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/exjobb\n",
        "!git status"
      ],
      "metadata": {
        "id": "ZUKmBi4IDmSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80ce057-b0a6-4f4f-ad25-866043d6ba64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/exjobb\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   miguel/datasets/tslj/N5 samples100 F_P60.npy\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmiguel/datasets/tslj/N100 samples100 F_P60.npy\u001b[m\n",
            "\t\u001b[31mmiguel/datasets/tslj/N1005 samples100 F_P60.npy\u001b[m\n",
            "\t\u001b[31mmiguel/datasets/tslj/N50 samples100 F_P60.npy\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "uD2_V9kBaYQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add miguel/datasets/tslj/N5\\ samples1000\\ F_P60.npy"
      ],
      "metadata": {
        "id": "gZZWuQmVkGhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Data after simulation periodic boundary fix\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vF-H0HpXXKi",
        "outputId": "f3588aaf-ade9-49e7-d107-23d9573e25ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 141f610] Data after simulation periodic boundary fix\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 miguel/datasets/tslj/N5 samples1000 F_P60.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remember to create new token for each use\n",
        "!git push https://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@github.com/Phistian/exjobb.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLdczHb-XWuN",
        "outputId": "93f91a70-98b6-447b-fecb-37f123cf1d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 10, done.\n",
            "Counting objects:  10% (1/10)\rCounting objects:  20% (2/10)\rCounting objects:  30% (3/10)\rCounting objects:  40% (4/10)\rCounting objects:  50% (5/10)\rCounting objects:  60% (6/10)\rCounting objects:  70% (7/10)\rCounting objects:  80% (8/10)\rCounting objects:  90% (9/10)\rCounting objects: 100% (10/10)\rCounting objects: 100% (10/10), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  16% (1/6)\rCompressing objects:  33% (2/6)\rCompressing objects:  50% (3/6)\rCompressing objects:  66% (4/6)\rCompressing objects:  83% (5/6)\rCompressing objects: 100% (6/6)\rCompressing objects: 100% (6/6), done.\n",
            "Writing objects:  16% (1/6)\rWriting objects:  33% (2/6)\rWriting objects:  50% (3/6)\rWriting objects:  66% (4/6)\rWriting objects:  83% (5/6)\rWriting objects: 100% (6/6)\rWriting objects: 100% (6/6), 356.97 KiB | 7.14 MiB/s, done.\n",
            "Total 6 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas:   0% (0/4)\u001b[K\rremote: Resolving deltas:  25% (1/4)\u001b[K\rremote: Resolving deltas:  50% (2/4)\u001b[K\rremote: Resolving deltas:  75% (3/4)\u001b[K\rremote: Resolving deltas: 100% (4/4)\u001b[K\rremote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/Phistian/exjobb.git\n",
            "   a70287f..141f610  main -> main\n"
          ]
        }
      ]
    }
  ]
}